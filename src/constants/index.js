// export const myProjects = [
//   {
//     id: 1,
//     title: "E‑Commerce SKU Sales Forecasting & Anomaly Detection",
//     discription: "Forecasted weekly sales for 200+ SKUs using Facebook Prophet, improving inventory accuracy by 25% and reducing stockouts.",
//     href: "",
//     image: "",
//     tags: [
//       { id: 1, name: "Python" },
//       { id: 2, name: "Facebook Prophet" },
//       { id: 3, name: "Anomaly Detection" },
//       { id: 4, name: "Tableau" },
//     ],
//   },
//   {
//     id: 2,
//     title: "End‑to‑End ETL from GA4 & HubSpot to PostgreSQL",
//     discription: " Developed an Airflow ETL pipeline integrating Google Analytics and HubSpot CRM into PostgreSQL, cutting data prep time by 40%",
//     href: "",
//     image: "",
//     tags: [
//       { id: 1, name: "Airflow" },
//       { id: 2, name: "PostgreSQL" },
//       { id: 3, name: "Google Analytics" },
//       { id: 4, name: "HubSpot" },
//       { id: 5, name: "ETL" },
//     ],
//   },
// ];

export const mySocials = [
  {
    name: "LinkedIn",
    href: "https://www.linkedin.com/in/scvd/",
    icon: "/assets/socials/linkedIn.svg",
  },
];

export const experiences = [
  {
    title: "Azure Data Engineer",
    job: "Hallmark Financial Services",
    date: "Jul. 2024 – Present",
    location: "Fort Worth, TX",
    contents: [
      "Engineered distributed ingestion across Azure Databricks, AWS Glue, and GCP Dataflow, boosting throughput by 35% and lowering analytics latency.",
      "Built enterprise data lakes/warehouses (ADLS, Redshift, BigQuery), improving query speed by 40% and reducing storage costs via partitioning and compression.",
      "Orchestrated batch/streaming ETL with Spark, Kafka, and Hadoop handling multi‑TB datasets and sub‑second real‑time ingestion.",
      "Established multi‑cloud CI/CD with Azure DevOps, Jenkins, Terraform, and Kubernetes, cutting deployments by 50% and ensuring reproducible releases.",
      "Delivered BI dashboards (Tableau, Power BI, Looker) for real‑time KPIs, accelerating executive decision‑making by 40%.",
      "Implemented governance (GDPR, CCPA), RBAC, and encryption for secure, audit‑ready hybrid architectures.",
      "Partnered with finance, actuarial, IT, and data science to enable predictive analytics and cost reductions via automation.",
    ],
  },
  {
    title: "AWS Data Engineer",
    job: "Tenet Healthcare Corporation",
    date: "Nov. 2022 – Jun. 2024",
    location: "Dallas, TX",
    contents: [
      "Automated ETL with AWS Glue, ADF, and GCP Dataflow, cutting prep time by 45% and enabling ML model access to clean data.",
      "Scaled real‑time ingestion with Kinesis, Event Hubs, and Kafka, increasing streaming throughput by 50% for patient and clinical data.",
      "Architected data warehouses (Redshift, Synapse, BigQuery), shortening query times by 40% and enabling cross‑cloud federated queries.",
      "Deployed CI/CD (CodePipeline, Azure DevOps, Jenkins) with Terraform and Kubernetes, streamlining releases by 55%.",
      "Delivered BI dashboards (Tableau, Power BI, Looker) for executives, accelerating strategic decision‑making by 35%.",
    ],
  },
  {
    title: "GCP Data Engineer",
    job: "Lumen Technologies (Accenture)",
    date: "Sep. 2021 – Jul. 2022",
    location: "Hyderabad, India",
    contents: [
      "Built multi‑cloud pipelines across AWS (Glue, Redshift, S3), Azure (Synapse, Databricks), and GCP (BigQuery, Dataflow, Dataproc) improving processing efficiency by 45%.",
      "Automated ETL/streaming with Spark, Kafka, Pub/Sub, Informatica, and Python handling 10M+ records/day and raising throughput by 50%.",
      "Delivered BI dashboards in Power BI/Tableau/Looker and enforced CI/CD, RBAC, and compliance (HIPAA, GDPR, CCPA).",
    ],
  },
  {
    title: "Data Engineer",
    job: "Boeing",
    date: "Jun. 2019 – Jul. 2021",
    location: "Hyderabad, India",
    contents: [
      "Designed high‑volume data pipelines using Python, PySpark, Hive SQL, Presto, and Cassandra/HDFS, improving query efficiency by 40%.",
      "Streamlined ETL with Spark, Hive, and SSIS, cutting transformation time by 50% via advanced SQL/Python cleansing.",
      "Deployed cloud‑native architectures with AWS, Docker, Kubernetes, and Jenkins CI/CD; delivered dashboards powered by BigQuery and Presto.",
    ],
  },
];
